# Design Decisions & Rationale

This document explains **why specific tools, techniques, and architectural
choices were made** while developing this project.  
It is intended to demonstrate a clear understanding of the system design,
trade-offs, and real-world considerations.

---

## 1️⃣ Why Retrieval Augmented Generation (RAG) Was Used

### Purpose
To reduce hallucination and ensure answers are grounded in real data.

### Reasoning
- Large Language Models (LLMs) alone generate answers based on learned patterns,
  not live or private data.
- RAG combines **retrieval + generation**, ensuring responses are based on
  retrieved documents.
- This makes the system more reliable, explainable, and production-ready.

### Outcome
- Answers are derived from actual document content.
- The system can be updated simply by changing stored documents, without
  retraining the model.

---

## 2️⃣ Why a Vector Database Was Needed

### Purpose
To enable semantic search rather than keyword-based search.

### Reasoning
- Keyword search fails when phrasing differs.
- Vector similarity captures **semantic meaning**, not exact words.
- Semantic search is foundational for modern AI applications such as
  RAG and recommendation systems.

### Outcome
- Queries retrieve relevant content even with different wording.
- Better recall and relevance compared to traditional keyword search.

---

## 3️⃣ Why Endee Was Chosen as the Vector Database

### Purpose
To use a high-performance, purpose-built vector database for semantic retrieval.

### Reasoning
- Endee is designed specifically for dense vector similarity search.
- It supports cosine similarity on high-dimensional embeddings.
- It aligns directly with semantic search and RAG use cases.

### Outcome
- Endee acts as the system’s **semantic memory**.
- Clear separation between machine learning logic and storage layer.

---

## 4️⃣ Why Sentence Transformers Were Used for Embeddings

### Purpose
To convert raw text into meaningful dense vector representations.

### Reasoning
- Sentence Transformers produce semantically rich embeddings.
- `all-MiniLM-L6-v2` is lightweight, fast, and widely adopted.
- It produces 384-dimensional vectors, compatible with the Endee index.

### Important Clarification
- Vectors are **never manually created**.
- All vectors are generated by a trained embedding model to preserve
  semantic meaning.

### Outcome
- Consistent semantic space for documents and queries.
- Reliable and meaningful similarity comparisons.

---

## 5️⃣ Why Text Chunking Was Used

### Purpose
To improve retrieval precision and relevance.

### Reasoning
- Large documents dilute semantic focus.
- Chunking enables fine-grained retrieval.
- Smaller chunks improve alignment between queries and document content.

### Outcome
- More precise retrieval.
- Better answer quality in the RAG pipeline.

---

## 6️⃣ Why an Extractive QA Model Was Used

### Purpose
To ensure answers come strictly from retrieved context.

### Reasoning
- Extractive QA models select answers directly from provided text.
- This prevents hallucinated or unsupported responses.
- Extractive outputs are easier to verify and explain.

### Outcome
- High trustworthiness.
- Clear grounding of answers in documents.

---

## 7️⃣ Why a Lightweight Agentic Layer Was Added

### Purpose
To introduce decision-making without instability.

### Reasoning
- Blind single-step retrieval may fail when similarity matches are weak.
- Evaluating similarity scores enables confidence-based decisions.
- Controlled logic avoids infinite loops and unpredictable behavior.

### Outcome
- Improved system reliability.
- Deterministic and explainable agent-like behavior.

---

## 8️⃣ Why UI-Based Vector Insertion Was Used

### Purpose
To adapt to current tooling limitations while preserving correctness.

### Reasoning
- Endee’s public ingestion APIs are currently limited.
- Vectors are still generated programmatically using an embedding model.
- UI-based insertion is a **transport workaround**, not a conceptual shortcut.

### Outcome
- Correct semantic pipeline is maintained.
- Integration approach is honest, documented, and aligned with real-world
  constraints.

---

## Summary

These design choices reflect a focus on:
- Correctness over shortcuts
- Explainability over black-box behavior
- Practical constraints over idealized assumptions
- Real-world engineering trade-offs

This ensures the system is both **technically sound** and **production-aware**.
